{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GiSnxJDrBvzH"
   },
   "source": [
    "## Verisetinin Yüklenmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pp6F_dK-BvzL"
   },
   "source": [
    "<span style=\"font-size:1.1em;\">Colab'a Google drive'ı entegre ediyoruz. Kullanılacak olan veriseti Google Drive'da bulunmaktadır</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eXSt9GwBvzO"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7duXtSRABvzY"
   },
   "outputs": [],
   "source": [
    "PREPROCESSED_DATASET_WITH_STEMMER = \"gdrive/My Drive/mbti/preprocessed_dataset_with_stemming.csv\"\n",
    "PREPROCESSED_DATASET_WITHOUT_STEMMER = \"gdrive/My Drive/mbti/preprocessed_dataset_no_stemming.csv\"\n",
    "PREPROCESSED_DATASET_ZEMBEREK = \"gdrive/My Drive/mbti/preprocessed_dataset_zemberek.csv\"\n",
    "ELIMINATED_DATASET = \"gdrive/My Drive/mbti/eliminated_all_users_v2.csv\"\n",
    "RAW_DATASET = \"gdrive/My Drive/mbti/all_users_v2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNsJolflBvzg"
   },
   "source": [
    "<span style=\"font-size:1.1em;\">Hangi veriseti kullanılarak işlem yapılacaksa yukardaki pathlerden biri seçilir ve parametre olarak verilir.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NN6XGz7OBvzj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(PREPROCESSED_DATASET_WITHOUT_STEMMER, sep = ';', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EiFZ5FBCBvzr"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkk5QQhHBvz0"
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZzvU-o2sc2w"
   },
   "source": [
    "<span style=\"font-size:1.1em;\">TF-IDF özellik vektörünün çıkartılmasında kullanılacak değişken aşağıda belirlenmiş olan parametrelerle oluşturulur.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbggMvzcY5ER"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzSU9aILsc2x"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p62dmJvNBv0J"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['entry'] = df['entry'].apply(lambda x: np.str_(x)) # ValueError: np.nan is an invalid document seklinde bir hata verdigi icin bunu asmak adina yapildi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0404NRDmBv0c"
   },
   "source": [
    "## Modelin Oluşturulması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JRTpmz32fOtg"
   },
   "source": [
    "<span style=\"font-size:1.1em;\">k-Fold Cross Validation yapılarak bütün veriseti üzerinde modelin test edilmesi sağlanmıştır. k değeri kadar veriseti parçaya bölünür. k-1 tane parça train set, geriye kalan 1 parça ise test set olarak ayrılır. Ve her iterasyon sonucunda bu parçalar değiştirilir.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbObRS01fIzb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kFold = KFold(n_splits = 5, shuffle = True, random_state = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGhowf9lZR44"
   },
   "source": [
    "Sonuçları kaydedilmek için dictionary oluşturulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYvOqK17ZRka"
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'predicted': {\n",
    "        'I': {'actual': {'I': 0, 'E': 0}},\n",
    "        'E': {'actual': {'I': 0, 'E': 0}},\n",
    "\n",
    "        'S': {'actual': {'S': 0, 'N': 0}},\n",
    "        'N': {'actual': {'S': 0, 'N': 0}},\n",
    "\n",
    "        'T': {'actual': {'T': 0, 'F': 0}},\n",
    "        'F': {'actual': {'T': 0, 'F': 0}},\n",
    "\n",
    "        'J': {'actual': {'J': 0, 'P': 0}},\n",
    "        'P': {'actual': {'J': 0, 'P': 0}},\n",
    "\n",
    "        'analysts': {'actual': {'analysts': 0, 'diplomats': 0, 'explorers': 0, 'sentinels': 0}},\n",
    "        'diplomats': {'actual': {'analysts': 0, 'diplomats': 0, 'explorers': 0, 'sentinels': 0}},\n",
    "        'explorers': {'actual': {'analysts': 0, 'diplomats': 0, 'explorers': 0, 'sentinels': 0}},\n",
    "        'sentinels': {'actual': {'analysts': 0, 'diplomats': 0, 'explorers': 0, 'sentinels': 0}}\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ClSceuobB22"
   },
   "source": [
    "**typeClass** tahmin edilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1skQ7bRfLyQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "iteration = 1\n",
    "\n",
    "for train_indices, test_indices in kFold.split(df):    \n",
    "  print(\"Started iteration: {}\".format(iteration))\n",
    "  train = df.iloc[train_indices]\n",
    "  X_train = train['entry']\n",
    "  y_train = train['typeClass']\n",
    "\n",
    "  test  = df.iloc[test_indices]\n",
    "  X_test = test['entry']    \n",
    "  y_test = test['typeClass']\n",
    "\n",
    "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "  X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
    "  X_train_tf = tf_transformer.transform(X_train_count)\n",
    "  X_test_tf = tf_transformer.transform(X_test_count)\n",
    "\n",
    "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "  y_test = y_test.values\n",
    "  y_predicted = clf.predict(X_test_tf)\n",
    "\n",
    "  print(\"Finished iteration: {}\".format(iteration))\n",
    "  iteration += 1\n",
    "  \n",
    "  for i in range(len(y_predicted)):\n",
    "    actual = y_test[i]\n",
    "    predicted = y_predicted[i]\n",
    "    results['predicted'][predicted]['actual'][actual] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o56cfw9zgtp0"
   },
   "source": [
    "**I/E** boyutu tahmin edilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajFgTew0gtT7"
   },
   "outputs": [],
   "source": [
    "iteration = 1\n",
    "\n",
    "for train_indices, test_indices in kFold.split(df):    \n",
    "  print(\"Started iteration: {}\".format(iteration))\n",
    "  train = df.iloc[train_indices]\n",
    "  X_train = train['entry']\n",
    "  y_train = train['I/E']\n",
    "\n",
    "  test  = df.iloc[test_indices]\n",
    "  X_test = test['entry']    \n",
    "  y_test = test['I/E']\n",
    "\n",
    "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "  X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
    "  X_train_tf = tf_transformer.transform(X_train_count)\n",
    "  X_test_tf = tf_transformer.transform(X_test_count)\n",
    "\n",
    "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "  y_test = y_test.values\n",
    "  y_predicted = clf.predict(X_test_tf)\n",
    "\n",
    "  print(\"Finished iteration: {}\".format(iteration))\n",
    "  iteration += 1\n",
    "  \n",
    "  for i in range(len(y_predicted)):\n",
    "    actual = y_test[i]\n",
    "    predicted = y_predicted[i]\n",
    "    results['predicted'][predicted]['actual'][actual] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHpkya56g2E8"
   },
   "source": [
    "**S/N** boyutu tahmin edilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mf4MXcmg5Q3"
   },
   "outputs": [],
   "source": [
    "iteration = 1\n",
    "\n",
    "for train_indices, test_indices in kFold.split(df):    \n",
    "  print(\"Started iteration: {}\".format(iteration))\n",
    "  train = df.iloc[train_indices]\n",
    "  X_train = train['entry']\n",
    "  y_train = train['S/N']\n",
    "\n",
    "  test  = df.iloc[test_indices]\n",
    "  X_test = test['entry']    \n",
    "  y_test = test['S/N']\n",
    "\n",
    "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "  X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
    "  X_train_tf = tf_transformer.transform(X_train_count)\n",
    "  X_test_tf = tf_transformer.transform(X_test_count)\n",
    "\n",
    "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "  y_test = y_test.values\n",
    "  y_predicted = clf.predict(X_test_tf)\n",
    "\n",
    "  print(\"Finished iteration: {}\".format(iteration))\n",
    "  iteration += 1\n",
    "  \n",
    "  for i in range(len(y_predicted)):\n",
    "    actual = y_test[i]\n",
    "    predicted = y_predicted[i]\n",
    "    results['predicted'][predicted]['actual'][actual] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9obMGboYhCm6"
   },
   "source": [
    "**T/F** boyutu tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrMA5CGGhGSF"
   },
   "outputs": [],
   "source": [
    "iteration = 1\n",
    "\n",
    "for train_indices, test_indices in kFold.split(df):    \n",
    "  print(\"Started iteration: {}\".format(iteration))\n",
    "  train = df.iloc[train_indices]\n",
    "  X_train = train['entry']\n",
    "  y_train = train['T/F']\n",
    "\n",
    "  test  = df.iloc[test_indices]\n",
    "  X_test = test['entry']    \n",
    "  y_test = test['T/F']\n",
    "\n",
    "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "  X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
    "  X_train_tf = tf_transformer.transform(X_train_count)\n",
    "  X_test_tf = tf_transformer.transform(X_test_count)\n",
    "\n",
    "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "  y_test = y_test.values\n",
    "  y_predicted = clf.predict(X_test_tf)\n",
    "\n",
    "  print(\"Finished iteration: {}\".format(iteration))\n",
    "  iteration += 1\n",
    "  \n",
    "  for i in range(len(y_predicted)):\n",
    "    actual = y_test[i]\n",
    "    predicted = y_predicted[i]\n",
    "    results['predicted'][predicted]['actual'][actual] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Ab40g8JhKDy"
   },
   "source": [
    "**J/P** boyutu tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdQaRJz3hKVe"
   },
   "outputs": [],
   "source": [
    "iteration = 1\n",
    "\n",
    "for train_indices, test_indices in kFold.split(df):    \n",
    "  print(\"Started iteration: {}\".format(iteration))\n",
    "  train = df.iloc[train_indices]\n",
    "  X_train = train['entry']\n",
    "  y_train = train['J/P']\n",
    "\n",
    "  test  = df.iloc[test_indices]\n",
    "  X_test = test['entry']    \n",
    "  y_test = test['J/P']\n",
    "\n",
    "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "  X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
    "  X_train_tf = tf_transformer.transform(X_train_count)\n",
    "  X_test_tf = tf_transformer.transform(X_test_count)\n",
    "\n",
    "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "  y_test = y_test.values\n",
    "  y_predicted = clf.predict(X_test_tf)\n",
    "\n",
    "  print(\"Finished iteration: {}\".format(iteration))\n",
    "  iteration += 1\n",
    "  \n",
    "  for i in range(len(y_predicted)):\n",
    "    actual = y_test[i]\n",
    "    predicted = y_predicted[i]\n",
    "    results['predicted'][predicted]['actual'][actual] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GkRGZ4XhSU0"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "naive-bayes_tf_all-users_k-fold",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
