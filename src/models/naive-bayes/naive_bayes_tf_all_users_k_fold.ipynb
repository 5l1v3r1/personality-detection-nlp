{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive-bayes_tf_all-users_k-fold",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpJPmp5PW1Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GiSnxJDrBvzH"
      },
      "source": [
        "## Verisetinin Yüklenmesi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pp6F_dK-BvzL"
      },
      "source": [
        "<span style=\"font-size:1.1em;\">Colab'a Google drive'ı entegre ediyoruz. Kullanılacak olan veriseti Google Drive'da bulunmaktadır</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0eXSt9GwBvzO",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7duXtSRABvzY",
        "colab": {}
      },
      "source": [
        "PREPROCESSED_DATASET_WITH_STEMMER = \"gdrive/My Drive/mbti/preprocessed_dataset_with_stemming.csv\"\n",
        "PREPROCESSED_DATASET_WITHOUT_STEMMER = \"gdrive/My Drive/mbti/preprocessed_dataset_no_stemming.csv\"\n",
        "PREPROCESSED_DATASET_ZEMBEREK = \"gdrive/My Drive/mbti/preprocessed_dataset_zemberek.csv\"\n",
        "TRIMMED_DATASET = \"gdrive/My Drive/mbti/trimmed_dataset.csv\"\n",
        "RAW_DATASET = \"gdrive/My Drive/mbti/all_users_v2.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xNsJolflBvzg"
      },
      "source": [
        "<span style=\"font-size:1.1em;\">Hangi veriseti kullanılarak işlem yapılacaksa yukardaki pathlerden biri seçilir ve parametre olarak verilir.</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NN6XGz7OBvzj",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv(PREPROCESSED_DATASET_WITHOUT_STEMMER, sep = ';', header = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EiFZ5FBCBvzr",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lkk5QQhHBvz0"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dZzvU-o2sc2w"
      },
      "source": [
        "<span style=\"font-size:1.1em;\">TF-IDF özellik vektörünün çıkartılmasında kullanılacak değişken aşağıda belirlenmiş olan parametrelerle oluşturulur.</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CbggMvzcY5ER",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wzSU9aILsc2x",
        "colab": {}
      },
      "source": [
        "count_vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p62dmJvNBv0J",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df['entry'] = df['entry'].apply(lambda x: np.str_(x)) # ValueError: np.nan is an invalid document seklinde bir hata verdigi icin bunu asmak adina yapildi."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0404NRDmBv0c"
      },
      "source": [
        "## Modelin Oluşturulması"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JRTpmz32fOtg"
      },
      "source": [
        "<span style=\"font-size:1.1em;\">k-Fold Cross Validation yapılarak bütün veriseti üzerinde modelin test edilmesi sağlanmıştır. k değeri kadar veriseti parçaya bölünür. k-1 tane parça train set, geriye kalan 1 parça ise test set olarak ayrılır. Ve her iterasyon sonucunda bu parçalar değiştirilir.</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CbObRS01fIzb",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold \n",
        "kFold = KFold(n_splits = 5, shuffle = True, random_state = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGhowf9lZR44",
        "colab_type": "text"
      },
      "source": [
        "Sonuçları kaydedilmek için dictionary oluşturulur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYvOqK17ZRka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = {\n",
        "    'predicted': {\n",
        "        'I': {'actual': {'I': 0, 'E': 0}},\n",
        "        'E': {'actual': {'I': 0, 'E': 0}},\n",
        "\n",
        "        'S': {'actual': {'S': 0, 'N': 0}},\n",
        "        'N': {'actual': {'S': 0, 'N': 0}},\n",
        "\n",
        "        'T': {'actual': {'T': 0, 'F': 0}},\n",
        "        'F': {'actual': {'T': 0, 'F': 0}},\n",
        "\n",
        "        'J': {'actual': {'J': 0, 'P': 0}},\n",
        "        'P': {'actual': {'J': 0, 'P': 0}},\n",
        "\n",
        "        'analysts': {'actual': {'analysts': 0, 'diplomats': 0, 'explorers': 0, 'sentinels': 0}},\n",
        "        'diplomats': {'actual': {'analysts': 0, 'diplomats': 0, 'explorers': 0, 'sentinels': 0}},\n",
        "        'explorers': {'actual': {'analysts': 0, 'diplomats': 0, 'explorers': 0, 'sentinels': 0}},\n",
        "        'sentinels': {'actual': {'analysts': 0, 'diplomats': 0, 'explorers': 0, 'sentinels': 0}}\n",
        "    }\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ClSceuobB22",
        "colab_type": "text"
      },
      "source": [
        "**typeClass** tahmin edilir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1skQ7bRfLyQ",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "iteration = 1\n",
        "\n",
        "for train_indices, test_indices in kFold.split(df):    \n",
        "  print(\"Started iteration: {}\".format(iteration))\n",
        "  train = df.iloc[train_indices]\n",
        "  X_train = train['entry']\n",
        "  y_train = train['typeClass']\n",
        "\n",
        "  test  = df.iloc[test_indices]\n",
        "  X_test = test['entry']    \n",
        "  y_test = test['typeClass']\n",
        "\n",
        "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
        "  X_test_count = count_vectorizer.transform(X_test)\n",
        "\n",
        "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
        "  X_train_tf = tf_transformer.transform(X_train_count)\n",
        "  X_test_tf = tf_transformer.transform(X_test_count)\n",
        "\n",
        "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
        "  y_test = y_test.values\n",
        "  y_predicted = clf.predict(X_test_tf)\n",
        "\n",
        "  print(\"Finished iteration: {}\".format(iteration))\n",
        "  iteration += 1\n",
        "  \n",
        "  for i in range(len(y_predicted)):\n",
        "    actual = y_test[i]\n",
        "    predicted = y_predicted[i]\n",
        "    results['predicted'][predicted]['actual'][actual] += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o56cfw9zgtp0",
        "colab_type": "text"
      },
      "source": [
        "**I/E** boyutu tahmin edilir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajFgTew0gtT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iteration = 1\n",
        "\n",
        "for train_indices, test_indices in kFold.split(df):    \n",
        "  print(\"Started iteration: {}\".format(iteration))\n",
        "  train = df.iloc[train_indices]\n",
        "  X_train = train['entry']\n",
        "  y_train = train['I/E']\n",
        "\n",
        "  test  = df.iloc[test_indices]\n",
        "  X_test = test['entry']    \n",
        "  y_test = test['I/E']\n",
        "\n",
        "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
        "  X_test_count = count_vectorizer.transform(X_test)\n",
        "\n",
        "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
        "  X_train_tf = tf_transformer.transform(X_train_count)\n",
        "  X_test_tf = tf_transformer.transform(X_test_count)\n",
        "\n",
        "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
        "  y_test = y_test.values\n",
        "  y_predicted = clf.predict(X_test_tf)\n",
        "\n",
        "  print(\"Finished iteration: {}\".format(iteration))\n",
        "  iteration += 1\n",
        "  \n",
        "  for i in range(len(y_predicted)):\n",
        "    actual = y_test[i]\n",
        "    predicted = y_predicted[i]\n",
        "    results['predicted'][predicted]['actual'][actual] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHpkya56g2E8",
        "colab_type": "text"
      },
      "source": [
        "**S/N** boyutu tahmin edilir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mf4MXcmg5Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iteration = 1\n",
        "\n",
        "for train_indices, test_indices in kFold.split(df):    \n",
        "  print(\"Started iteration: {}\".format(iteration))\n",
        "  train = df.iloc[train_indices]\n",
        "  X_train = train['entry']\n",
        "  y_train = train['S/N']\n",
        "\n",
        "  test  = df.iloc[test_indices]\n",
        "  X_test = test['entry']    \n",
        "  y_test = test['S/N']\n",
        "\n",
        "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
        "  X_test_count = count_vectorizer.transform(X_test)\n",
        "\n",
        "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
        "  X_train_tf = tf_transformer.transform(X_train_count)\n",
        "  X_test_tf = tf_transformer.transform(X_test_count)\n",
        "\n",
        "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
        "  y_test = y_test.values\n",
        "  y_predicted = clf.predict(X_test_tf)\n",
        "\n",
        "  print(\"Finished iteration: {}\".format(iteration))\n",
        "  iteration += 1\n",
        "  \n",
        "  for i in range(len(y_predicted)):\n",
        "    actual = y_test[i]\n",
        "    predicted = y_predicted[i]\n",
        "    results['predicted'][predicted]['actual'][actual] += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9obMGboYhCm6",
        "colab_type": "text"
      },
      "source": [
        "**T/F** boyutu tahmin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrMA5CGGhGSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iteration = 1\n",
        "\n",
        "for train_indices, test_indices in kFold.split(df):    \n",
        "  print(\"Started iteration: {}\".format(iteration))\n",
        "  train = df.iloc[train_indices]\n",
        "  X_train = train['entry']\n",
        "  y_train = train['T/F']\n",
        "\n",
        "  test  = df.iloc[test_indices]\n",
        "  X_test = test['entry']    \n",
        "  y_test = test['T/F']\n",
        "\n",
        "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
        "  X_test_count = count_vectorizer.transform(X_test)\n",
        "\n",
        "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
        "  X_train_tf = tf_transformer.transform(X_train_count)\n",
        "  X_test_tf = tf_transformer.transform(X_test_count)\n",
        "\n",
        "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
        "  y_test = y_test.values\n",
        "  y_predicted = clf.predict(X_test_tf)\n",
        "\n",
        "  print(\"Finished iteration: {}\".format(iteration))\n",
        "  iteration += 1\n",
        "  \n",
        "  for i in range(len(y_predicted)):\n",
        "    actual = y_test[i]\n",
        "    predicted = y_predicted[i]\n",
        "    results['predicted'][predicted]['actual'][actual] += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ab40g8JhKDy",
        "colab_type": "text"
      },
      "source": [
        "**J/P** boyutu tahmin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdQaRJz3hKVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iteration = 1\n",
        "\n",
        "for train_indices, test_indices in kFold.split(df):    \n",
        "  print(\"Started iteration: {}\".format(iteration))\n",
        "  train = df.iloc[train_indices]\n",
        "  X_train = train['entry']\n",
        "  y_train = train['J/P']\n",
        "\n",
        "  test  = df.iloc[test_indices]\n",
        "  X_test = test['entry']    \n",
        "  y_test = test['J/P']\n",
        "\n",
        "  X_train_count = count_vectorizer.fit_transform(X_train)\n",
        "  X_test_count = count_vectorizer.transform(X_test)\n",
        "\n",
        "  tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
        "  X_train_tf = tf_transformer.transform(X_train_count)\n",
        "  X_test_tf = tf_transformer.transform(X_test_count)\n",
        "\n",
        "  clf = MultinomialNB().fit(X_train_tf, y_train)\n",
        "  y_test = y_test.values\n",
        "  y_predicted = clf.predict(X_test_tf)\n",
        "\n",
        "  print(\"Finished iteration: {}\".format(iteration))\n",
        "  iteration += 1\n",
        "  \n",
        "  for i in range(len(y_predicted)):\n",
        "    actual = y_test[i]\n",
        "    predicted = y_predicted[i]\n",
        "    results['predicted'][predicted]['actual'][actual] += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GkRGZ4XhSU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}